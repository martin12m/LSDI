# import torch
# from torch.utils.data import Dataset, DataLoader
# import pandas as pd
# import numpy as np
# import os
# import torch.nn as nn
# import torch.nn.functional as F

# # Define device
# device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# # Paths to data
# relational_folder = "relational_tables_csv_botafogo"
# non_relational_folder = "transformed_datasets_botafogo"
# labels_path = "labels.csv"

# class TableDataset(Dataset):
#     def __init__(self, relational_folder, non_relational_folder, labels_path, target_size=1024):
#         self.relational_folder = relational_folder
#         self.non_relational_folder = non_relational_folder
#         self.labels = pd.read_csv(labels_path)
#         self.table_ids = self.labels["table_id"].values
#         self.transformations = self.labels["transformation"].values
#         self.target_size = target_size  # Desired size of flattened tensors

#         # Map transformations to numerical labels
#         self.transformation_mapping = {t: i for i, t in enumerate(self.labels["transformation"].unique())}

#     def preprocess_table(self, df):
#         """Convert the table to numeric format and ensure consistent size."""
#         df = df.select_dtypes(include=[np.number]).fillna(0)
#         flat_array = df.to_numpy(dtype=np.float32).flatten()
#         if len(flat_array) > self.target_size:
#             flat_array = flat_array[:self.target_size]
#         else:
#             flat_array = np.pad(flat_array, (0, self.target_size - len(flat_array)), mode="constant")
#         return flat_array

#     def __len__(self):
#         return len(self.table_ids)

#     def __getitem__(self, idx):
#         table_id = self.table_ids[idx]
#         relational_path = os.path.join(self.relational_folder, f"{table_id}.csv")
#         non_relational_path = os.path.join(self.non_relational_folder, f"non_relational_{table_id}.csv")

#         # Load relational and non-relational tables
#         relational = pd.read_csv(relational_path)
#         non_relational = pd.read_csv(non_relational_path)

#         # Preprocess tables
#         relational_tensor = torch.tensor(self.preprocess_table(relational), dtype=torch.float32)
#         non_relational_tensor = torch.tensor(self.preprocess_table(non_relational), dtype=torch.float32)

#         # Label as the transformation index
#         label = self.transformation_mapping[self.transformations[idx]]

#         return non_relational_tensor, relational_tensor, torch.tensor(label, dtype=torch.long)

# # Create dataset and DataLoader
# dataset = TableDataset(relational_folder, non_relational_folder, labels_path)
# dataloader = DataLoader(dataset, batch_size=32, shuffle=True)

# class TransformationModel(nn.Module):
#     def __init__(self, num_classes):
#         super(TransformationModel, self).__init__()
#         # Convolutional layers
#         self.conv1 = nn.Conv1d(1, 16, kernel_size=3, stride=1, padding=1)
#         self.conv2 = nn.Conv1d(16, 32, kernel_size=3, stride=1, padding=1)
#         self.conv3 = nn.Conv1d(32, 64, kernel_size=3, stride=1, padding=1)
#         self.pool = nn.MaxPool1d(kernel_size=2, stride=2)

#         # Fully connected layers
#         self.fc1 = nn.Linear(64 * 256, 128)  # 64 channels * 256 size = 16384
#         self.fc2 = nn.Linear(128, num_classes)

#     def forward(self, x):
#         x = x.unsqueeze(1)  # Add channel dimension
#         x = F.relu(self.conv1(x))
#         x = self.pool(F.relu(self.conv2(x)))
#         x = self.pool(F.relu(self.conv3(x)))
#         x = x.view(x.size(0), -1)  # Flatten

#         operator_out = F.relu(self.fc1(x))
#         operator_out = self.fc2(operator_out)

#         return operator_out  # Only return operator_out

# # Initialize model
# num_classes = len(dataset.labels["transformation"].unique())
# model = TransformationModel(num_classes)

# # Move model to device
# model.to(device)

# # Define loss and optimizer
# criterion_operator = nn.CrossEntropyLoss()
# optimizer = torch.optim.Adam(model.parameters(), lr=0.001)

# # Training the model
# num_epochs = 10
# model.train()

# for epoch in range(num_epochs):
#     total_loss = 0
#     correct = 0
#     total = 0

#     for non_relational, relational, labels in dataloader:
#         # Move tensors to the device
#         non_relational = non_relational.to(device)
#         labels = labels.to(device)

#         # Forward pass
#         operator_out = model(non_relational)

#         # Compute loss
#         loss_operator = criterion_operator(operator_out, labels)
#         loss = loss_operator  # Only operator loss

#         # Backward pass and optimization
#         optimizer.zero_grad()
#         loss.backward()
#         optimizer.step()

#         # Track metrics
#         total_loss += loss.item()
#         _, predicted = torch.max(operator_out, 1)
#         correct += (predicted == labels).sum().item()
#         total += labels.size(0)

#     # Print epoch metrics
#     accuracy = 100 * correct / total
#     print(f"Epoch [{epoch + 1}/{num_epochs}], Loss: {total_loss:.4f}, Accuracy: {accuracy:.2f}%")

# # Save model
# torch.save(model.state_dict(), "transformation_model.pth")
# print("Model saved successfully!")



import torch
from torch.utils.data import Dataset, DataLoader
import pandas as pd
import numpy as np
import os
import torch.nn as nn
import torch.nn.functional as F

# Set device for computation
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# Define paths for data
RELATIONAL_FOLDER = "relational_tables_csv_botafogo"
NON_RELATIONAL_FOLDER = "transformed_datasets_botafogo"
LABELS_PATH = "labels.csv"

class TableDataset(Dataset):
    def __init__(self, relational_folder, non_relational_folder, labels_path, target_size=1024):
        self.relational_folder = relational_folder
        self.non_relational_folder = non_relational_folder
        self.labels = pd.read_csv(labels_path)
        self.table_ids = self.labels["table_id"].values
        self.transformations = self.labels["transformation"].values
        self.target_size = target_size

        # Create a mapping from transformation names to numerical labels
        self.transformation_mapping = {transformation: idx for idx, transformation in enumerate(self.labels["transformation"].unique())}

    def preprocess_table(self, df):
        """Convert DataFrame to a flattened numeric tensor of fixed size."""
        numeric_data = df.select_dtypes(include=[np.number]).fillna(0)
        flat_array = numeric_data.to_numpy(dtype=np.float32).flatten()
        return self._adjust_size(flat_array)

    def _adjust_size(self, array):
        """Ensure the array is of the target size by padding or truncating."""
        if len(array) > self.target_size:
            return array[:self.target_size]
        return np.pad(array, (0, self.target_size - len(array)), mode="constant")

    def __len__(self):
        return len(self.table_ids)

    def __getitem__(self, idx):
        table_id = self.table_ids[idx]
        relational_path = os.path.join(self.relational_folder, f"{table_id}.csv")
        non_relational_path = os.path.join(self.non_relational_folder, f"non_relational_{table_id}.csv")

        # Load and preprocess the tables
        relational_tensor = torch.tensor(self.preprocess_table(pd.read_csv(relational_path)), dtype=torch.float32)
        non_relational_tensor = torch.tensor(self.preprocess_table(pd.read_csv(non_relational_path)), dtype=torch.float32)

        # Get the corresponding label
        label = self.transformation_mapping[self.transformations[idx]]

        return non_relational_tensor, relational_tensor, torch.tensor(label, dtype=torch.long)

# Initialize dataset and DataLoader
dataset = TableDataset(RELATIONAL_FOLDER, NON_RELATIONAL_FOLDER, LABELS_PATH)
dataloader = DataLoader(dataset, batch_size=32, shuffle=True)

class TransformationModel(nn.Module):
    def __init__(self, num_classes):
        super(TransformationModel, self).__init__()
        self.conv_layers = nn.Sequential(
            nn.Conv1d(1, 16, kernel_size=3, padding=1),
            nn.ReLU(),
            nn.Conv1d(16, 32, kernel_size=3, padding=1),
            nn.ReLU(),
            nn.MaxPool1d(kernel_size=2, stride=2),
            nn.Conv1d(32, 64, kernel_size=3, padding=1),
            nn.ReLU(),
            nn.MaxPool1d(kernel_size=2, stride=2)
        )
        self.fc_layers = nn.Sequential(
            nn.Linear(64 * 256, 128),  # Adjust based on input size
            nn.ReLU(),
            nn.Linear(128, num_classes)
        )

    def forward(self, x):
        x = x.unsqueeze(1)  # Add channel dimension
        x = self.conv_layers(x)
        x = x.view(x.size(0), -1)  # Flatten
        return self.fc_layers(x)

# Instantiate the model
num_classes = len(dataset.labels["transformation"].unique())
model = TransformationModel(num_classes).to(device)

# Define loss function and optimizer
criterion = nn.CrossEntropyLoss()
optimizer = torch.optim.Adam(model.parameters(), lr=0.001)

# Training loop
def train_model(model, dataloader, criterion, optimizer, num_epochs=10):
    model.train()
    for epoch in range(num_epochs):
        total_loss, correct, total = 0, 0, 0

        for non_relational, _, labels in dataloader:
            non_relational, labels = non_relational.to(device), labels.to(device)

            # Forward pass
            outputs = model(non_relational)

            # Compute loss
            loss = criterion(outputs, labels)

            # Backward pass and optimization
            optimizer.zero_grad()
            loss.backward()
            optimizer.step()

            # Track metrics
            total_loss += loss.item()
            _, predicted = torch.max(outputs, 1)
            correct += (predicted == labels).sum().item()
            total += labels.size(0)

        # Print epoch metrics
        accuracy = 100 * correct / total
        print(f"Epoch [{epoch + 1}/{num_epochs}], Loss: {total_loss:.4f}, Accuracy: {accuracy:.2f}%")

# Start training the model
train_model(model, dataloader, criterion, optimizer)

# Save the trained model
torch.save(model.state_dict(), "transformation_model.pth")
print("Model saved successfully!")